#' @title Analyze sonde drift/mis-cal data in the context of drift
#' @author Guy Litt
#' @description Reads in data generated by the nightly alerts for drift detection.
#' This script identifies
#' the longest temporal gap in the data and assumes that before the gap 
#' represents pre-calibration data (grp1) and after the gap represents post-cal (grp2). 
#' Characteristics (e.g. mean/std dev of pre-post S1-S2 differenced groups) are then
#' recalculated.
#' 
#' 
#' 
#' @details Matched sonde data generated by flow.rtrn.alrt.snde.dtct.drft.R, 
#' nightly in the IS-monitoring pipeline


#' @notes Should only consider data after Aug 1, 2019. Before that, the sonde
#' was likely not wiping at all sites, with site-by-site fixes occurring May through
#' July 2019.
#' 
# Changelog / contributions
#  2022-05-06 beginning to craft analysis

# TODO change this logic to entirely use the maximum gap as the presumed calibration period
#      (rather than keeping pre-post readings that worked from cluster analysis)
# TODO and then ensure consistent calculations of pre-post metrics for all calibrations


# TODO consider further adapting flow.snde.dtct.drft.R to extract more information useful for drift WG

# TODO Should consider fulcrum data and field-recorded biofouling. Ignore drift analyses where those data indicate non-'light' biofouling.



library(iRobert.base)  # Present on dev-2 as of Spring, 2022
library(eddycopipe) # Present on dev-2 as of Spring, 2022
library(alerts) # Present on dev-2 as of Spring, 2022


funcDir <- "~/R/NEON-drift-correction/pack/"
sapply(list.files(funcDir, pattern = ".R"), function(x) source(paste0(funcDir,x)))
# Read bucket
bucket <- iRobert.base::wrap.set.creds.based.on.server() # poorly designed function for general application. Must be on dev-2 or prod-2
metaDirXtra <- "metadata/sondeDrift/xtra/"

# Fulcrum data inside neon-dev-is-sensor-health-data bucket (only includs some fulcrum data):
datFlcm <- eddycopipe::wrap_neon_gcs_read(object = paste0("metadata/sondeDrift/ais_sonde_fulcrum_prod.rds"), bucket = bucket)

# (Includes all fulcrum data)
flcmCredPath = "/opt/apps/is_monitoring_pipeline/no_creds_in_the_repo/.fulcrum_creds.RDS" # path in dev-2
# Set fulcrum Creds:
if(base::file.exists(flcmCredPath)){
  CRED_FLCM <- base::readRDS(flcmCredPath)
} else {
  msgNoFlcmDbCred <- paste0("PROBLEM: The fulcrum credentials file does not exist in ", flcmCredPath)
  rlog$error(msgNoFlcmDbCred)
  print(msgNoFlcmDbCred)
  stop(msgNoFlcmDbCred)
}

# Write bucket:
bucketWrte <- "neon-dev-is-drift"

# Directory for saving intermediate work
saveDirTemp <- "~/analysesQAQC/drift/sondeDrift/"
if(!dir.exists(saveDirTemp)){
  dir.create(saveDirTemp,recursive=TRUE)
}

timeCol <- "timeRndMin"
nameS1 <- "data.101.100"
nameS2 <- "data.102.100"


# List data from neon-dev-is-sensor-health
allObjBckt <-  eddycopipe::neon_gcs_list_objects(bucket = bucket,
                                                 prefix = metaDirXtra)

aisSitz <- c()

dpDataSubStr <- base::gsub(metaDirXtra,"",allObjBckt$Key) %>% base::gsub(pattern = ".rds", replacement = "")
dtSplt <- lapply(dpDataSubStr, function(x) transpose(as.data.table(strsplit(x,split = "_")[[1]] ) )) %>%  rbindlist()
names(dtSplt) <- paste0(c("dpId","type","date"))

dtSplt$site <- unlist(lapply(dtSplt$dpId, function(x) strsplit(x, split=".",fixed=TRUE)[[1]][[2]]))
dtSplt$termStr <- unlist(lapply(dtSplt$dpId, function(x) strsplit(x, split=".",fixed=TRUE)[[1]][[6]]))
dtSplt$termNum <- stringr::str_extract_all(dtSplt$termStr, "\\(?[0-9,.]+\\)?","")

dtObj <- cbind(allObjBckt,dtSplt)

typzAnls <- unique(dtSplt$type)

clstRsltObj <- dtObj[grep("kMeansClstrRsltData", dtObj$Key), ]



if(!file.exists(paste(saveDirTemp,"rsltDiffSndeGrpClstReCalc.csv"))){
  lsRsltDiff <- base::list()
  
  for(idx in 1:nrow(clstRsltObj)){
    clstRslt <- eddycopipe::neon_gcs_get_rds(bucket = bucket,object = clstRsltObj$Key[idx]) %>% data.table::as.data.table()
    clstRslt$timeRndMin <- base::as.POSIXct(clstRslt$timeRndMin, tz = "UTC")
    
    # TODO Re-assign kMeans cluster values...
    namzRedo <- c("grp", "kMeanDiff","sdDiffClst",
                  "medianClst1_101.100","medianClst2_101.100",
                  "medianClst1_102.100","medianClst2_102.100")
    
    clstRslt <- as.data.frame(clstRslt) %>% select(-dplyr::all_of(namzRedo))
    

    
    #Extract information of interest:
    
    dfRsltDiff <- data.table::data.table()#matrix(nrow=1, ncol=1))
    # The last difference reading of group 1, and first difference reading of group 2
    dfRsltDiff$date <- as.Date(clstRslt$timeRndMin[1] )
    dfRsltDiff$site <- clstRsltObj$site[idx]
    dfRsltDiff$term <- clstRsltObj$termNum[idx]
    
    # -------------------- Alternative gap identification ------------------ #
    wideData <- reshape2::melt(data = clstRslt,id.vars = timeCol,
                               measure.vars = c(nameS1,nameS2))
    # wideData <- wideData[order(wideData[[timeCol]]),]
    reLong <- reshape2::dcast(wideData,formula= timeRndMin~variable, value.var = "value")
    reLong <- reLong[order(reLong[,timeCol]),]
    tDiff <- diff(reLong[[timeCol]],lag=1)
    
    
    idxPre <- which.max(tDiff)
    idxPost <- idxPre + 1
    endTimePre <- reLong[idxPre,timeCol]
    bgnTimePost <- reLong[idxPost,timeCol]
    
    gapDur <- difftime(bgnTimePost,endTimePre,units="mins")
    # TODO double check this is correct. Can S1 and S2 have varying time gaps???
    
    
    dfRsltDiff$endTimePre <- endTimePre
    dfRsltDiff$bgnTimePost <- bgnTimePost
    dfRsltDiff$gapDur <- gapDur
    
    # TODO Based on gap duration, consider pre-cal and post-cal natural fluctuations within the same time duration
    
  
    # Redefine the cluster groups to represent pre-cal and post-cal
    clstRslt$grp <- NA
    clstRslt$grp[1:idxPre] <- 1
    clstRslt$grp[idxPost:nrow(clstRslt)] <- 2
    
    # --------- 
    idxsGrp2 <- which(clstRslt$grp == 2)
    idxsGrp1 <- which(clstRslt$grp ==1)
    grp1 <- clstRslt[-idxsGrp2,]
    grp2 <- clstRslt[idxsGrp2,]
    maxGrp1 <- which.max(grp1$timeRndMin)
    minGrp2 <- which.min(grp2$timeRndMin)
    # --

    # TODO not sure if this is the correct calculation on mean of difference
    
    grp1$kMeanDiff <- base::mean(grp1$diff)
    grp2$kMeanDiff <- base::mean(grp2$diff)
    grp1$sdDiffClst <- stats::sd(grp1$diff)
    grp2$sdDiffClst <- stats::sd(grp2$diff)
    
    clstRslt$kMeanDiff <- NA
    clstRslt$sdDiffClst <- NA
    clstRslt[idxsGrp1,"kMeanDiff"] <- base::mean(grp1$diff)
    clstRslt[idxsGrp2,"kMeanDiff"] <- base::mean(grp2$diff)
    clstRslt[idxsGrp1,"sdDiffClst"] <- stats::sd(grp1$diff)
    clstRslt[idxsGrp2,"sdDiffClst"] <- stats::sd(grp2$diff)
    
    
    clstRslt$medianClst1_101.100 <- NA
    clstRslt$medianClst1_102.100 <- NA
    clstRslt$medianClst2_101.100 <- NA
    clstRslt$medianClst2_102.100 <- NA
    clstRslt[,"medianClst1_101.100"] <- stats::median(grp1$data.101.100)
    clstRslt[,"medianClst1_102.100"] <- stats::median(grp1$data.102.100)
    clstRslt[,"medianClst2_101.100"] <- stats::median(grp2$data.101.100)
    clstRslt[,"medianClst2_102.100"] <- stats::median(grp2$data.102.100)
    
  
    
    
    # Difference between pre-and-post cal readings
    dfRsltDiff$preDiff <- grp1$diff[maxGrp1]
    dfRsltDiff$postDiff <- grp2$diff[minGrp2]
    dfRsltDiff$changeSngl <-  dfRsltDiff$postDiff -  dfRsltDiff$preDiff
    
    dfRsltDiff$mednAccS1 <- stats::median(clstRslt$accS1)
    dfRsltDiff$mednAccS2 <- stats::median(clstRslt$accS2)
    dfRsltDiff$mednCmboAcc <- stats::median(clstRslt$cmboAcc)
    
    if(grp2$timeRndMin[minGrp2] < grp1$timeRndMin[maxGrp1]){
      cat(paste0(dfRsltDiff$site," ",dfRsltDiff$term, " ",dfRsltDiff$date, " did not exhibit defined clusters."))
      dfRsltDiff$defnClstGrp <- FALSE  # cluster grouping poorly-defined.
      stop()
      # TODO attempt to define pre-post cal groupings differently (e.g. search for gaps)
      
    
      
      
      if(length(which(is.na(wideData))) > 10){
        warning(paste0("More than 10 data points NA, index: ",idx) )
      }
      # Assumption: The longest time gap corresponds to sensor maintenance
      
      
      
      
    
    } else {
      dfRsltDiff$defnClstGrp <- TRUE # cluster grouping well-defined.
      
      if(all(maxGrp1-29 > 0)){
        dfRsltDiff$preDiffMedn30 <- median(grp1$diff[(maxGrp1-29):maxGrp1])
      } else {
        dfRsltDiff$preDiffMedn30 <- NA
      }
      
      if(all(minGrp2+29 <= nrow(minGrp2))){
        dfRsltDiff$postDiffMedn30 <- median(grp2$diff[minGrp2:(minGrp2+29)])
      } else {
        dfRsltDiff$postDiffMedn30 <- NA
      }
      
      dfRsltDiff$changeMedn30 <-  dfRsltDiff$postDiffMedn30 -  dfRsltDiff$preDiffMedn30
      dfRsltDiff$kMeanDiffGrp1 <- unique(grp1$kMeanDiff)
      dfRsltDiff$kMeanDiffGrp2 <- unique(grp2$kMeanDiff)
      dfRsltDiff$sdDiffClstGrp1 <- unique(grp1$sdDiffClst)
      dfRsltDiff$sdDiffClstGrp2 <- unique(grp2$sdDiffClst)
      
    }
    
    lsRsltDiff[[idx]] <- data.table::as.data.table(dfRsltDiff)
  }
  
  rsltDiff <- data.table::rbindlist(lsRsltDiff, fill=TRUE)
  
  write.csv(rsltDiff,paste(saveDirTemp,"rsltDiffSndeGrpClstReCalc.csv"))
} else {
  # TODO Write results to drift bucket:
  # def.set.gcp.env(bucket=bucketWrite)
  rsltDiff <- read.csv(paste0(saveDirTemp,"rsltDiffSndeGrpClstReCalc.csv"))
}



# =========================================================================== #
#             Reduce dataset to times when calibration was performed
# =========================================================================== #

# The rsltDiffSndeGrpClstReCalc considers both cleaning-only bouts and re-cal bouts
# Use fulcrum data to distinguish between cleaning vs. recalibrations:


flcmParaList = base::list(vec_col_namz = c("siteid", "date","location_stream",
                                           "level_of_s1_biofouling","level_of_s2_biofouling", "post_cleaning_do", "s2post_cleaning_do", "s1_post_cal_ph","s2_post_cal_ph","ph_comparison_successful",
                                           "sonde_calibrated",
                                           "s1_post_cal_conductivity","s2_post_cal_conductivity"),
                          siteid = "ALL",
                          flcmDateCol = "date")

datFlcm <- alerts::def.grab.flcm.app(apiToken = CRED_FLCM, start_date= "2018-01-01",
                                     end_date = max(rsltDiff$date),
                                     vec_col_namz = flcmParaList$vec_col_namz,
                                     siteid = flcmParaList$siteid,
                                     dateCol = flcmParaList$flcmDateCol,
                                     verbose=FALSE,
                                     formId = "3be325c3-dc74-4010-8cf6-24ee0d447094")
datFlcm <- datFlcm[base::order(datFlcm[,flcmParaList$flcmDateCol]),]

head(datFlcm)
# Any data point that had at least one calibration (S1, S2, or both) could be useful for drift analysis
idxsCalS2 <- (which(!is.na(datFlcm$s2_post_cal_ph)))
idxsCalS1 <- (which(!is.na(datFlcm$s1_post_cal_ph)))
idxsCalComp <- (which(!is.na(datFlcm$ph_comparison_successful)))

idxsCal <- unique(sort(c(idxsCalS1,idxsCalS2,idxsCalComp)))
# Site-dates calibration:

siteDatzCal <- unique(datFlcm[idxsCal, c("siteid","date")])
siteDatzCal$date <- as.Date(siteDatzCal$date)
dim(siteDatzCal)



siteDatzCal$siteDate <- paste0(siteDatzCal$siteid,"_",siteDatzCal$date)

rsltDiff$siteDate <- paste0(rsltDiff$site,"_",rsltDiff$date)

idxsCal <- which(rsltDiff$siteDate %in% siteDatzCal$siteDate)
idxsCln <- which(!rsltDiff$siteDate %in% siteDatzCal$siteDate)

length(idxsCln)
length(idxsCal)

rsltCal <- rsltDiff[idxsCal,]
rsltCln <- rsltDiff[idxsCln,]
summary(as.numeric(rsltCln$gapDur))

# =========================================================================== #
#         Analyze sequence of calibration results by site               
# =========================================================================== #


# TODO visits with time gaps <10 mins probably are faulty/shouldn't be in here.
units(rsltCal$gapDur)

idxsTooShort <- which(rsltCal$gapDur < 30)

rsltCalb <- rsltCal[-idxsTooShort,]

rsltCal$gapDur[idxsTooShort]

idxs

# Premise: for e/ site, look at sequence of pre-post calibration assessment results
# Classify whether something is drift or mis-calibration
# Then filter further by considering biofouling fulcrum records.


for(site in unique(rsltCalb$site)){
  
  rsltCalbSite <- rsltCalb[grep(site,rsltCalb$site),]
  
  for(term in unique(rsltCalbSite$term)){
    idxsTerm <- which(rsltCalbSite$term == term)
    subTrm <- rsltCalbSite[idxsTerm,]
    if(base::nrow(subTrm)==0){
      next()
    }
    
    
    # Now try to identify potential instances of drift, as differenced values
    #  beyond the accuracy reading. Note that YSI published accuracy is defined in the 
    # Para_EXO_accuracy.csv within the alerts package parameter files, and
    #  alerts::def.calc.acc.val() chooses the largest accuracy value b/w absolute
    # The combined accuracy between S1 and S2 is then calculated.
    
    hist(subTrm$changeMedn30)
    
    # Ensure data.frame ordered by time
    subTrm <- subTrm[order(subTrm$date),]
    
   
    
    # The indices of data falling outside of expected range
    idxsAbovUncn <- which(abs(subTrm$changeSngl) > subTrm$mednCmboAcc)
    
    # Consider the 
    idxsAbovUncnPos <- which(subTrm$changeSngl > subTrm$mednCmboAcc)
    idxsAbovUncnNeg <- which(subTrm$changeSngl < -subTrm$mednCmboAcc)
    
    
    diff(idxsAbovUncn)
    
    
    
    hist(subTrm$changeMedn30[idxsAbovUncn])  
    
  }
}


head(clstRsltObj$Key)

# TODO subset by site, calculate the direction of drift correction (t2 - t1 value), then 



unique(clstRslt$)








clstRsltMelt <- clstRslt %>% select(dplyr::all_of(c(timeCol,nameS1,nameS2))) %>%
  reshape2::melt(measure.vars = c(nameS1, nameS2))



ggplot2::ggplot(clstRsltMelt,aes_string(x=timeCol, y = "value", color = "variable")) + 
  geom_line()
